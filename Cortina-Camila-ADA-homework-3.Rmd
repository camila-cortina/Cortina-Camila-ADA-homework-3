---
title: "Cortina-Camila-ADA-homework-3"
author: "Camila Cortina"
date: "4/29/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

##Challenge 1
```{r}
library(readr)
library(tidyverse)
library(ggplot2)
library(tidyr)
library(broom)
library(infer)
#importing dataset
d<- read_csv("KamilarAndCooperData.csv", col_names = TRUE)

model<- lm(MaxLongevity_m ~ Brain_Size_Species_Mean, data=d)
summary(model)
#The slope of B1 is 1.2180

#90% CI for the slope 
alpha<-.1
(CI <- tidy(model, conf.int = TRUE, conf.level = 1-alpha))

#90% Confidence Intervals 
sd <- glance(model) %>% pull(sigma) # sd deviation of residuals
ci <- model %>% augment() %>%
  mutate(
    c.lwr = .fitted - qt(1 - alpha/2, nrow(d) - 2) * .se.fit,
    c.upr = .fitted + qt(1 - alpha/2, nrow(d) - 2) * .se.fit,
    se.prediction = sqrt(sd^2 + .se.fit^2),
    p.lwr = .fitted - qt(1 - alpha / 2, nrow(d) - 2) * se.prediction,
    p.upr = .fitted + qt(1 - alpha / 2, nrow(d) - 2) * se.prediction
  )

#creating regression models
colors<- c("CI" = "blue", "PI" = "red")
ggplot(d, aes(x=Brain_Size_Species_Mean, y=MaxLongevity_m)) + geom_point() + geom_smooth(method = "lm", se = FALSE, color = "black") + annotate("text", label = "longevity ~ brain size", x = 150, y = 950, size = 4, colour = "red") + geom_line(data = ci, aes(x= Brain_Size_Species_Mean, y = c.lwr), color = "blue") + geom_line(data = ci, aes(x = Brain_Size_Species_Mean, y = c.upr, color = "CI")) + geom_line(data = ci, aes(x = Brain_Size_Species_Mean, y = p.lwr, color = "PI")) + geom_line(data = ci, aes(x = Brain_Size_Species_Mean, y = p.upr), color = "red") + guides(col = guide_legend()) + labs(x = "Species Average Brain Size", y = "Max Longevity") +  scale_color_manual(name = "Legend", values = colors)

#predicting the longevity at 750gm Brain Size
coeffs = coefficients(model)
brain = 750          
longevity = coeffs[1] + coeffs[2]*brain 
longevity 

pi750 <- predict(model,
  newdata = data.frame(Brain_Size_Species_Mean = 750),
  interval = "prediction", level = 0.9)
pi750
#The longevity of a species with a 750 mg brain is 1162.445 +/- 196
#I do not trust the model to make predictions about the longevity at this large of a brain size because there are very few points as the brain size gets larger and the confidence levels are very wide at this point, coming closer and closer to the prediction intervals as the brain size gets larger, which are not a good prediction of the longevity. 

#Doing it for log-transformed data
log_model<- lm(log(MaxLongevity_m) ~ log(Brain_Size_Species_Mean), data=d)
summary(log_model)

#90% CI for the slope 
alpha<-.1
(CI <- tidy(log_model, conf.int = TRUE, conf.level = 1-alpha))

#90% Confidence Intervals 
sd <- glance(log_model) %>% pull(sigma) # sd deviation of residuals
ci <- log_model %>% augment() %>%
  mutate(
    c.lwr = .fitted - qt(1 - alpha / 2, nrow(d) - 2) * .se.fit,
    c.upr = .fitted + qt(1 - alpha / 2, nrow(d) - 2) * .se.fit,
    se.prediction = sqrt(sd^2 + .se.fit^2),
    p.lwr = .fitted - qt(1 - alpha / 2, nrow(d) - 2) * se.prediction,
    p.upr = .fitted + qt(1 - alpha / 2, nrow(d) - 2) * se.prediction
  )

ggplot(d, aes(x=log(Brain_Size_Species_Mean), y=log(MaxLongevity_m))) + geom_point() + geom_smooth(method = "lm", se = FALSE, color = "black") + annotate("text", label = "log(longevity) ~ log(brain size)", x = 2.55, y = 6.65, size = 4, colour = "red") + geom_line(data = ci, aes(x= log.Brain_Size_Species_Mean., y = c.lwr, color = "CI")) + geom_line(data = ci, aes(x = log.Brain_Size_Species_Mean., y = c.upr), color = "blue") + geom_line(data = ci, aes(x = log.Brain_Size_Species_Mean., y = p.lwr, color = "PI")) + geom_line(data = ci, aes(x = log.Brain_Size_Species_Mean., y = p.upr), color = "red") + labs(x = "Species Average Brain Size", y = "Max Longevity") +  scale_color_manual(name = "Legend", values = colors)

#predicting the longevity at 750gm Brain Size
coeffs = coefficients(log_model)
brain = log(750)       
longevity = coeffs[1] + coeffs[2]*brain 
longevity 

pi750 <- predict(log_model,
  newdata = data.frame(Brain_Size_Species_Mean = 750),
  interval = "prediction", level = 0.9)
pi750
#The longevity of a species with a 750 mg brain on the log scale is 6.429 +/- .422
 

#The log transformed model is better because more of the points fall on the line created by the regression. In the untransformed model, most of the points are centered on the left-hand side of the graph and therefore the prediction of where the points will be with larger brain sizes is less accurate. This can be seen in the confidence interval and how it is further away from the line the larger the brain size is. 
```

##Challenge 2
```{r}
homerange_model<- lm(log(HomeRange_km2) ~ log(Body_mass_female_mean), data = d)
summary(homerange_model) 
#The slope is 1.036 and the intercept is -9.441

#bootstrap to sample the model 1000 times, got it to work with the for loop too
d$logHomeRange<- log(d$HomeRange_km2)
d$logBody<- log(d$Body_mass_female_mean)
boot.slope <- d %>%
  specify(logHomeRange ~ logBody) %>%
  generate(reps = 1000, type = "bootstrap") %>%
  calculate(stat = "slope")
head(boot.slope)

n_boot <- 1000
boot <- vector(length = n_boot) 
boot.slope <- vector(length = n_boot) #maybe take out
n <- length(d)
for (i in 1:1000) {
  d_temp<- dplyr::sample_n(d, n, replace = TRUE)
  #d_temp$logHomeRange<- log(d_temp$HomeRange_km2)
  #d_temp$logBody<- log(d_temp$Body_mass_female_mean)
  boot[[i]] <- coefficients(lm(log(HomeRange_km2) ~ log(Body_mass_female_mean), data = d_temp))[1]
   boot.slope[[i]] <- coefficients(lm(log(HomeRange_km2) ~ log(Body_mass_female_mean), data = d_temp))[2]
}

#plotting the histogram
hist(boot.slope,
  main = "Histogram of Bootstrapped\nSlope Values",
  xlab = "Slope Coefficient")

hist(boot, xlab = "Intercept Coefficients", main = "Bootstrapped Sampling Distribution \n of Intercept Values")

#Standard Error for B coefficients
# first define alpha, CI boundaries, and critical values
alpha <- 0.05
confidence_level <- 1 - alpha
p_lower <- alpha / 2
p_upper <- 1 - (alpha / 2)
degrees_of_freedom <- nrow(d) - 2
critical_value <- qt(p_upper, df = degrees_of_freedom)

#Estimate the SE and the CI for slope
boot.slope<- data.frame(boot.slope)
boot.slope.summary <- boot.slope %>%
  summarize(
    estimate = mean(boot.slope),
    std.error = sd(boot.slope),
    # calculate the CI based on the quantile (percentile)  method
    boot.lower = quantile(boot.slope, p_lower),
    boot.upper = quantile(boot.slope, p_upper)
  )
boot.slope.summary

#Estimate the SE and the CI for intercept 
boot<- data.frame(boot)
boot.int.summary <- boot %>%
  summarize(
    estimate = mean(boot),
    std.error = sd(boot),
    # calculate the CI based on the quantile (percentile)  method
    boot.lower = quantile(boot, p_lower),
    boot.upper = quantile(boot, p_upper)
  )
boot.int.summary

#The SEs estimated by bootstrapping are slightly lower (.0771) than using the lm function (.08488) for the slope, but higher for the intercept (1.444 vs. .673)

#The CIs from bootstrapping are slightly lower when using the lm function than with bootstrapping
confint(homerange_model)

```

##Challenge 3
```{r}
boot_lm<- function(d, model, conf.level = .95, reps = 1000){
  model<- lm(model, data = d)
  model_coeffs<- summary(model)
  n_boot <- reps
  boot <- vector(length = n_boot) 
  boot.slope <- vector(length = n_boot)
  n <- length(d)
for (i in 1:reps) {
  d_temp<- dplyr::sample_n(d, n, replace = TRUE)
  boot[[i]] <- coefficients(lm(model, data = d_temp))[1]
  boot.slope[[i]] <- coefficients(lm(model, data = d_temp))[2]
}
  alpha <- 1 - conf.level
confidence_level <- conf.level
p_lower <- alpha / 2
p_upper <- 1 - (alpha / 2)
degrees_of_freedom <- nrow(d) - 2
critical_value <- qt(p_upper, df = degrees_of_freedom)

#Estimate the SE and the CI for slope
boot.slope<- data.frame(boot.slope)
boot.slope.summary <- boot.slope %>%
  summarize(
    estimate = mean(boot.slope),
    std.error = sd(boot.slope),
    # calculate the CI based on the quantile (percentile)  method
    boot.lower = quantile(boot.slope, p_lower),
    boot.upper = quantile(boot.slope, p_upper)
  )
#Estimate the SE and the CI for intercept 
boot<- data.frame(boot)
boot.int.summary <- boot %>%
  summarize(
    estimate = mean(boot),
    std.error = sd(boot),
    # calculate the CI based on the quantile (percentile)  method
    boot.lower = quantile(boot, p_lower),
    boot.upper = quantile(boot, p_upper)
  )
final_return<- list(model_coeffs, mean(boot$boot), mean(boot.slope$boot.slope), boot.slope.summary, boot.int.summary)
return(final_return)

}
#Running the function for the following models:
#log(HomeRange_km2) ~ log(Body_mass_female_mean)
boot_lm(d = d, model = "log(HomeRange_km2) ~ log(Body_mass_female_mean)")
#log(HomeRange_km2) ~ log(Body_mass_female_mean)
boot_lm(d =d, model = "log(HomeRange_km2) ~ log(Body_mass_female_mean)")
#log(HomeRange_km2) ~ log(Body_mass_female_mean) + MeanGroupSize
boot_lm(d = d, model = "log(HomeRange_km2) ~ log(Body_mass_female_mean) + MeanGroupSize")
```

##Extra Credit
```{r}
boot_reps = seq(from = 10, to = 200, by = 10)
extra_output <- array(list(), 20)
for (i in 1:20) {
extra_output[[i]]<- boot_lm(d = d, model = "log(HomeRange_km2) ~ log(Body_mass_female_mean)", reps = boot_reps[i])
}
mean_output<- vector(length = 20) 
lower_CI<- vector(length = 20)
upper_CI<- vector(length = 20)
for (i in 1:20) {
mean_output[[i]] <- extra_output[[i]][[3]]  
lower_CI[[i]] <- extra_output[[i]][[4]]$boot.lower
upper_CI[[i]]<- extra_output[[i]][[4]]$boot.upper
}
plot_output<- data.frame(mean = mean_output, lower_CI = lower_CI, upper_CI = upper_CI, reps = seq(from = 10, to = 200, by = 10))

ggplot(plot_output, aes(x = reps, y = mean)) + geom_line() + geom_line(data = plot_output, aes(x = reps, y = lower_CI)) + geom_line(data = plot_output, aes(x = reps, y = upper_CI)) + geom_hline(yintercept = 1.03, color = "red")
```





